import streamlit as st
import pandas as pd
from pathlib import Path

def render_standard_master_view(selected_name: str, file_path: Path, header_map: dict):
    """Render a standard master data management page [v2.6]."""
    
    st.markdown("""
        <style>
        div[data-testid="stToast"] {
            position: fixed;
            top: 20px;
            right: 50%;
            transform: translateX(50%);
            z-index: 9999;
            background-color: #2e7d32;
            color: white;
            border-radius: 10px;
            box-shadow: 0 4px 15px rgba(0,0,0,0.2);
        }
        </style>
    """, unsafe_allow_html=True)

    st.header(f"ğŸ“š {selected_name} ê´€ë¦¬ [v2.6]")
    st.markdown(f"ì‹ì•½ì²˜ ê¸°ì¤€ì •ë³´({selected_name}) ë°ì´í„°ë¥¼ ì¡°íšŒí•˜ê³  ìˆ˜ì •í•©ë‹ˆë‹¤.")
    
    if not file_path.exists():
        st.error(f"âš ï¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}")
        return

    try:
        # Load full dataset
        df_full = pd.read_parquet(file_path, engine='pyarrow')
        
        # Initialize IS_MANUAL_FIXED if missing
        if 'IS_MANUAL_FIXED' not in df_full.columns:
            df_full['IS_MANUAL_FIXED'] = False
            
        st.info(f"ğŸ“Š ë¡œë“œ ì™„ë£Œ: {len(df_full):,}ê±´ì˜ ë ˆì½”ë“œ (ìˆ˜ë™ ê´€ë¦¬ ëŒ€ìƒ í¬í•¨)")
        
        # 1. Search filter
        if selected_name == "FDA Import Alert ê´€ë¦¬":
            if not st.session_state.get("fda_show_all", False):
                df_filtered = df_full[df_full['IsCollect'] == True].copy()
            else:
                df_filtered = df_full.copy()
        else:
            df_filtered = df_full.copy()
        
        if selected_name in ["ê°œë³„ê¸°ì¤€ê·œê²©", "ê³µí†µê¸°ì¤€ê·œê²©"]:
            st.markdown("ğŸ” **ìƒì„¸ í•„í„° (Multi-Select)**")
            
            k_prod = f"f_prod_{selected_name}"
            k_test = f"f_test_{selected_name}"
            
            # Use 2-column layout for hierarchical filtering (Product -> Test)
            cols = st.columns(2)
            
            # 1. Product Name (Single Select)
            prod_opts = ["ì „ì²´"] + sorted(df_full['PRDLST_CD_NM'].dropna().unique().astype(str).tolist())
            sel_prod = cols[0].selectbox("í’ˆëª©ëª… ì„ íƒ (ë‹¨ì¼)", options=prod_opts, key=k_prod)
            
            # 2. Test Name (Dependent Multiselect)
            if sel_prod != "ì „ì²´":
                test_opts = sorted(df_full[df_full['PRDLST_CD_NM'] == sel_prod]['TESTITM_NM'].dropna().unique().astype(str).tolist())
            else:
                test_opts = sorted(df_full['TESTITM_NM'].dropna().unique().astype(str).tolist())
            
            f_test = cols[1].multiselect("ì‹œí—˜í•­ëª©ëª… ì„ íƒ (ë³µìˆ˜)", options=test_opts, key=k_test)
            
            # Filtering logic
            if sel_prod == "ì „ì²´":
                if f_test:
                    df_filtered = df_full[df_full['TESTITM_NM'].isin(f_test)]
                else:
                    df_filtered = df_full.copy()
            else:
                mask = (df_full['PRDLST_CD_NM'] == sel_prod)
                if f_test:
                    mask = mask & df_full['TESTITM_NM'].isin(f_test)
                df_filtered = df_full[mask]
            
            if sel_prod != "ì „ì²´" or f_test:
                st.success(f"ğŸ” í•„í„° ê²°ê³¼: {len(df_filtered):,}ê±´")


        else:
            # 1.5. Master Code Search Helper (FDA Only) - Moved and Expanded per user request
            if selected_name in ["FDA Import Alert ê´€ë¦¬", "FDA í’ˆëª©ìœ í˜• ë§¤í•‘"]:
                with st.expander("ğŸ” ì‹ì•½ì²˜ í’ˆëª©/ì‹œí—˜í•­ëª© ì½”ë“œ ê²€ìƒ‰ ë„ìš°ë¯¸ (ìˆ˜ë™ ë§¤í•‘ìš©)", expanded=True):
                    t1, t2 = st.tabs(["í’ˆëª© ê²€ìƒ‰", "Hazard(ì‹œí—˜í•­ëª©) ê²€ìƒ‰"])
                    with t1:
                        p_master_path = Path("data/reference/product_code_master.parquet")
                        if p_master_path.exists():
                            p_df_m = pd.read_parquet(p_master_path)
                            p_lookup = p_df_m.set_index('PRDLST_CD')['KOR_NM'].to_dict()
                            p_df_m['ìƒìœ„í’ˆëª©ëª…'] = p_df_m['HRNK_PRDLST_CD'].map(p_lookup).fillna("-")
                            p_df_m['ìµœìƒìœ„í’ˆëª©ëª…'] = p_df_m['HTRK_PRDLST_CD'].map(p_lookup).fillna("-")
                            
                            search_opts = sorted(p_df_m['KOR_NM'].dropna().unique().tolist())
                            p_sel = st.selectbox("í’ˆëª©ëª… ê²€ìƒ‰ (ê²€ìƒ‰ í›„ í’ˆëª©ëª…ê³¼ í’ˆëª©ì½”ë“œë¥¼ ë³µì‚¬í•˜ì—¬ ì‚¬ìš©í•˜ì„¸ìš”.)", options=search_opts, index=None, placeholder="í‚¤ì›Œë“œ ì…ë ¥ ë˜ëŠ” ì„ íƒ...", key="helper_ps")
                            
                            if p_sel:
                                res_p = p_df_m[p_df_m['KOR_NM'] == p_sel].copy()
                                st.dataframe(
                                    res_p[['KOR_NM', 'PRDLST_CD', 'ìƒìœ„í’ˆëª©ëª…', 'ìµœìƒìœ„í’ˆëª©ëª…']].rename(columns={
                                        'KOR_NM': 'í•œê¸€ëª…', 'PRDLST_CD': 'í’ˆëª©ì½”ë“œ'
                                    }),
                                    width='stretch', hide_index=True
                                )
                        else:
                            st.warning("í’ˆëª© ë§ˆìŠ¤í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    
                    with t2:
                        h_master_path = Path("data/reference/hazard_code_master.parquet")
                        k_master_path = Path("data/reference/keyword_map_master.parquet")
                        
                        if h_master_path.exists():
                            h_df_m = pd.read_parquet(h_master_path)
                            
                            # Load and merge keyword map entries if available
                            if k_master_path.exists():
                                try:
                                    k_df_m = pd.read_parquet(k_master_path)
                                    # Treat TESTITM_NM from keyword map same as standard ones
                                    # Ensure we only use the common columns to avoid fragmentation
                                    h_cols = ['TESTITM_NM', 'TESTITM_CD', 'M_KOR_NM', 'L_KOR_NM']
                                    k_df_subset = k_df_m[[c for c in h_cols if c in k_df_m.columns]].copy()
                                    
                                    # Combine and drop duplicates based on name
                                    combined_hazards = pd.concat([h_df_m[h_cols], k_df_subset], ignore_index=True)
                                    combined_hazards = combined_hazards.drop_duplicates(subset=['TESTITM_NM']).sort_values('TESTITM_NM')
                                except Exception as e:
                                    st.warning(f"í‚¤ì›Œë“œ ë§¤í•‘ ë°ì´í„° ë³‘í•© ì‹¤íŒ¨: {e}")
                                    combined_hazards = h_df_m.sort_values('TESTITM_NM')
                            else:
                                combined_hazards = h_df_m.sort_values('TESTITM_NM')
                            
                            h_opts = combined_hazards['TESTITM_NM'].dropna().unique().tolist()
                            h_sel = st.selectbox("ì‹œí—˜í•­ëª© ê²€ìƒ‰ (ë§ˆìŠ¤í„° ë°ì´í„° ë° í‚¤ì›Œë“œ ë§¤í•‘ ì „ì²´)", options=h_opts, index=None, placeholder="ì‹œí—˜í•­ëª©ëª… ì…ë ¥ ë˜ëŠ” ì„ íƒ...", key="helper_hs")
                            
                            if h_sel:
                                res_h = combined_hazards[combined_hazards['TESTITM_NM'] == h_sel]
                                
                                if not res_h.empty:
                                    st.dataframe(
                                        res_h[['TESTITM_NM', 'TESTITM_CD', 'M_KOR_NM', 'L_KOR_NM']].rename(columns={
                                            'TESTITM_NM': 'ì‹œí—˜í•­ëª©ëª…', 'TESTITM_CD': 'ì‹œí—˜í•­ëª©ì½”ë“œ', 
                                            'M_KOR_NM': 'ì¤‘ë¶„ë¥˜', 'L_KOR_NM': 'ëŒ€ë¶„ë¥˜'
                                        }),
                                        width='stretch', hide_index=True
                                    )
                        else:
                            st.warning("ì‹œí—˜í•­ëª© ë§ˆìŠ¤í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

            search_term = st.text_input(
                f"ğŸ” {selected_name} í‚¤ì›Œë“œ ê²€ìƒ‰",
                placeholder="í’ˆëª©ëª…, ì½”ë“œ ë“± ì•„ë¬´ í‚¤ì›Œë“œë‚˜ ì…ë ¥í•˜ì„¸ìš”...",
                key=f"search_{selected_name}"
            )
            if search_term:
                mask = df_filtered.apply(
                    lambda x: x.astype(str).str.contains(search_term, case=False, na=False).any(),
                    axis=1
                )
                df_filtered = df_filtered[mask].copy()
                st.success(f"ğŸ” ê²€ìƒ‰ ê²°ê³¼: {len(df_filtered):,}ê±´")


        # 2. Interactive editor
        st.markdown("---")
        st.subheader("âœï¸ ë°ì´í„° í¸ì§‘ê¸°")
        
        if selected_name == "FDA Import Alert ê´€ë¦¬":
            st.info("ğŸ’¡ **ëª¨ë‹ˆí„°ë§ ì—¬ë¶€ ì„¤ì • ê¸°ì¤€**: ì‹í’ˆë§Œ í•´ë‹¹ (ì˜ë£Œê¸°ê¸° ë“± ì œì™¸ / Green Listë§Œ ìˆëŠ” ê²½ìš° ì œì™¸, ìˆ˜ì • ê°€ëŠ¥)")
            st.toggle("ë¹„ëª¨ë‹ˆí„°ë§ í•­ëª© í¬í•¨ (ì „ì²´ ë³´ê¸°)", value=False, key="fda_show_all")
        
        # Identify columns to hide (Codes and Dates as requested)
        if selected_name == "ê°œë³„ê¸°ì¤€ê·œê²©":
            # Specific refined list for Individual Spec Management
            SPEC_SHOW_COLS = [
                "PRDLST_CD_NM", "TESTITM_NM", "SPEC_VAL", "UNIT_NM", 
                "SPEC_VAL_SUMUP", "MXMM_VAL", "A081_FNPRT_CD_NM", 
                "MIMM_VAL", "A080_FNPRT_CD_NM", 
                "A082_CF_FNPRT_CD_NM", "A082_CI_FNPRT_CD_NM", 
                "IS_MANUAL_FIXED"
            ]
            cols_to_show = [c for c in SPEC_SHOW_COLS if c in header_map]
        elif selected_name == "ê³µí†µê¸°ì¤€ê·œê²©":
            # Specific refined list for Common Spec Management
            CMMN_SHOW_COLS = [
                "PRDLST_CD_NM", "SPEC_NM", "TESTITM_NM", "PIAM_KOR_NM", 
                "SPEC_VAL", "UNIT_NM", "SPEC_VAL_SUMUP", 
                "MXMM_VAL", "A081_FNPRT_CD_NM", "MIMM_VAL", "A080_FNPRT_CD_NM", 
                "A082_CF_FNPRT_CD_NM", "A082_CI_FNPRT_CD_NM", 
                "MCRRGNSM_2N", "MCRRGNSM_2C", "MCRRGNSM_2M", "MCRRGNSM_3M", 
                "SORC", "IS_MANUAL_FIXED"
            ]
            cols_to_show = [c for c in CMMN_SHOW_COLS if c in header_map]
        elif selected_name == "FDA Import Alert ê´€ë¦¬":
            # FDA Management: Hide auto-filled hierarchy/classes to declutter
            FDA_SHOW_COLS = [
                "Alert_No", "IsCollect", "Title", "OASIS_Charge_Code_Line", "Product_Description",
                "Manual_Product_Type_NM", "Manual_Product_Type", 
                "Manual_Hazard_Item", "Manual_Hazard_Item_CD",
                "Has_Red_List", "Has_Yellow_List", "Has_Green_List", "Last_Updated_Date", "URL"
            ]
            cols_to_show = [c for c in FDA_SHOW_COLS if c in header_map]
        elif selected_name == "FDA í’ˆëª©ìœ í˜• ë§¤í•‘":
            # Show mapping fields, hiding auto-filled hierarchy names for cleaner UI
            MAPPING_SHOW_COLS = [
                "FDA_CODE", "ENG_NM", "KOR_NM", "PRDLST_CD", "IS_MANUAL_FIXED"
            ]
            cols_to_show = [c for c in MAPPING_SHOW_COLS if c in header_map]
        else:
            HIDE_KEYWORDS = ["ì½”ë“œ", "ì¼ì", "ì¼ì‹œ", "ì‹œí€€ìŠ¤", "ì¼ë ¨ë²ˆí˜¸"]
            cols_to_show = []
            for eng_col, kor_col in header_map.items():
                if not any(k in kor_col for k in HIDE_KEYWORDS):
                    cols_to_show.append(eng_col)
            
            # Always include IS_MANUAL_FIXED if it's in the map
            if 'IS_MANUAL_FIXED' not in cols_to_show and 'IS_MANUAL_FIXED' in header_map:
                cols_to_show.append('IS_MANUAL_FIXED')
            
        # Versioning for total Refresh
        if f"edit_v_{selected_name}" not in st.session_state:
            st.session_state[f"edit_v_{selected_name}"] = 0
            
        ed_key = f"ed_{selected_name}_v2_{st.session_state[f'edit_v_{selected_name}']}"
        
        # Filter for visible columns only
        display_df = df_filtered.copy()
        display_df = display_df[cols_to_show]
        
        # Row limit for performance (prevent websocket limit issues)
        MAX_DISPLAY_ROWS = 5000
        is_limited = False

        if len(display_df) > MAX_DISPLAY_ROWS:
            display_df = display_df.head(MAX_DISPLAY_ROWS)
            is_limited = True
            st.warning(f"âš ï¸ ë°ì´í„°ê°€ ë„ˆë¬´ ë§ì•„ ìƒìœ„ {MAX_DISPLAY_ROWS:,}ê±´ë§Œ í‘œì‹œí•©ë‹ˆë‹¤. ì „ì²´ ë°ì´í„°ë¥¼ ë³´ë ¤ë©´ í•„í„°ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.")
            
        display_df = display_df.rename(columns=header_map)
        
        # Configure columns dynamically
        col_config = {}
        disabled_cols = []
        
        if selected_name == "FDA Import Alert ê´€ë¦¬":
            col_config["ìƒì„¸ ë§í¬"] = st.column_config.LinkColumn(
                display_text="ë§í¬",
                width="small"
            )
            # FDA Management: Hide auto-filled hierarchy/classes to declutter
            FDA_SHOW_COLS = [
                "Alert_No", "IsCollect", "Title", "OASIS_Charge_Code_Line", "Product_Description",
                "Manual_Product_Type_NM", "Manual_Product_Type", 
                "Manual_Hazard_Item", "Manual_Hazard_Item_CD",
                "Has_Red_List", "Has_Yellow_List", "Last_Updated_Date", "URL"
            ]
            # Since we renamed columns, checking against header_map values is tricky?
            # header_map maps "Title_KR" -> "ì œëª©".
            # display_df has "ì œëª©".
            # cols_to_show logic: `[c for c in COLS if c in header_map]` -> returns keys.
            # But earlier `df_full` filtering used keys.
            # `standard_view.py` logic around line 107 in my view was:
            # `cols_to_show = [c for c in FDA_SHOW_COLS if c in header_map]`
            # This logic selects KEYS.
            # But line 118 `cols_to_show` is used where? 
            # It's NOT used in `st.data_editor(display_df)` directly?
            # Wait, `display_df` contains ALL columns by default unless filtered?
            # `standard_view.py` usually does `display_df = display_df[cols_to_show]`?
            # I need to check if I missed that logic.
            
            # Re-reading lines 118-140 via context I recall:
            # `if cols_to_show: display_df = display_df[cols_to_show]`
            # Yes. 
            # Since I changed FDA_SHOW_COLS to use "Title_KR", and `header_map` has "Title_KR", it works.
            
            # Disable editing for auto-collected fields (Use Display Names)
            disabled_cols = [
                "Alert ë²ˆí˜¸", "ì œëª©", "ì˜¤ì•„ì‹œìŠ¤ ì½”ë“œ", "ì œí’ˆ ì„¤ëª… í—¤ë”", 
                "ìµœì¢… ì—…ë°ì´íŠ¸ì¼", "Red List ì—¬ë¶€", "Yellow List ì—¬ë¶€",
                "ìƒìœ„í’ˆëª©", "ìµœìƒìœ„í’ˆëª©", "ì¤‘ë¶„ë¥˜", "ëŒ€ë¶„ë¥˜"
            ]
        elif selected_name == "FDA í’ˆëª©ìœ í˜• ë§¤í•‘":
            # Disable hierarchy names and parent codes as they are auto-looked up
            disabled_cols = ["ìƒìœ„í’ˆëª©ëª…", "ìµœìƒìœ„í’ˆëª©ëª…", "ìƒìœ„í’ˆëª©ì½”ë“œ", "ìµœìƒìœ„í’ˆëª©ì½”ë“œ"]

        edited_raw = st.data_editor(
            display_df,
            num_rows="dynamic",
            width='stretch',
            height=600,
            key=ed_key,
            column_config=col_config,
            disabled=disabled_cols
        )
        
        def perform_final_save(current_df, changes_map, editor_df):
            try:
                import time
                # 1. Deletions
                d_rows = changes_map.get('deleted_rows', [])
                if d_rows:
                    current_df = current_df.drop(index=display_df.index[d_rows])
                
                # 2. Edits (Auto manual flag)
                e_rows = changes_map.get('edited_rows', {})
                manual_col_display = header_map.get('IS_MANUAL_FIXED', 'ìˆ˜ë™ê³ ì •ì—¬ë¶€')
                
                for r_idx_s, r_diff in e_rows.items():
                    target = display_df.index[int(r_idx_s)]
                    if target in current_df.index and manual_col_display not in r_diff:
                        editor_df.loc[target, manual_col_display] = True
                
                # 3. Final Merge
                reverse_map = {v: k for k, v in header_map.items()}
                merged = editor_df.rename(columns=reverse_map)
                
                # 4. New Rows Integration
                new_idx = merged.index.difference(current_df.index)
                if not new_idx.empty:
                    merged.loc[new_idx, 'IS_MANUAL_FIXED'] = True
                
                # [Custom Logic] FDA Product Mapping Enrichment
                if selected_name == "FDA í’ˆëª©ìœ í˜• ë§¤í•‘":
                    master_path = Path("data/reference/product_code_master.parquet")
                    if master_path.exists():
                        try:
                            m_df = pd.read_parquet(master_path)
                            # Create maps
                            name_map = m_df.set_index('PRDLST_CD')['KOR_NM'].to_dict()
                            parent_map = m_df.set_index('PRDLST_CD')['HRNK_PRDLST_CD'].to_dict()
                            top_map = m_df.set_index('PRDLST_CD')['HTRK_PRDLST_CD'].to_dict()
                            
                            def enrich_row(row):
                                code = str(row.get('PRDLST_CD', '')).strip()
                                if code and code in name_map:
                                    p_code = parent_map.get(code)
                                    t_code = top_map.get(code)
                                    row['HRNK_PRDLST_CD'] = p_code
                                    row['HTRK_PRDLST_CD'] = t_code
                                    row['HRNK_KOR_NM'] = name_map.get(p_code) if p_code else None
                                    row['HTRK_KOR_NM'] = name_map.get(t_code) if t_code else None
                                return row
                            
                            merged = merged.apply(enrich_row, axis=1)
                        except Exception as e:
                            st.warning(f"Hierarchy enrichment failed: {e}")
                
                # [Custom Logic] FDA Import Alert Enrichment
                elif selected_name == "FDA Import Alert ê´€ë¦¬":
                    prod_master_path = Path("data/reference/product_code_master.parquet")
                    haz_master_path = Path("data/reference/hazard_code_master.parquet")
                    
                    try:
                        # 1. Product Hierarchy Enrichment (By Code Priority)
                        if prod_master_path.exists():
                            m_df = pd.read_parquet(prod_master_path)
                            p_name_map = m_df.set_index('PRDLST_CD')['KOR_NM'].to_dict()
                            p_rev_map = m_df.set_index('KOR_NM')['PRDLST_CD'].to_dict() # Multiple codes possible, but we take latest/one
                            p_parent_map = m_df.set_index('PRDLST_CD')['HRNK_PRDLST_CD'].to_dict()
                            p_top_map = m_df.set_index('PRDLST_CD')['HTRK_PRDLST_CD'].to_dict()
                            
                            def enrich_prod(row):
                                code = str(row.get('Manual_Product_Type', '')).strip()
                                name = str(row.get('Manual_Product_Type_NM', '')).strip()
                                
                                # Priority 1: Fill Name from Code
                                if code and code in p_name_map:
                                    row['Manual_Product_Type_NM'] = p_name_map.get(code)
                                # Priority 2: Fill Code from Name
                                elif name and name in p_rev_map:
                                    code = p_rev_map.get(name)
                                    row['Manual_Product_Type'] = code
                                
                                if code and code in p_name_map:
                                    p_code = p_parent_map.get(code)
                                    t_code = p_top_map.get(code)
                                    row['Manual_HRNK_NM'] = p_name_map.get(p_code) if p_code else None
                                    row['Manual_HTRK_NM'] = p_name_map.get(t_code) if t_code else None
                                return row
                            merged = merged.apply(enrich_prod, axis=1)

                        # 2. Hazard Category Enrichment
                        if haz_master_path.exists():
                            h_df = pd.read_parquet(haz_master_path)
                            h_m_map = h_df.set_index('TESTITM_NM')['M_KOR_NM'].to_dict()
                            h_l_map = h_df.set_index('TESTITM_NM')['L_KOR_NM'].to_dict()
                            h_c_map = h_df.set_index('TESTITM_NM')['TESTITM_CD'].to_dict()
                            h_rev_map = h_df.set_index('TESTITM_CD')['TESTITM_NM'].to_dict()
                            
                            def enrich_haz(row):
                                name = str(row.get('Manual_Hazard_Item', '')).strip()
                                code = str(row.get('Manual_Hazard_Item_CD', '')).strip()
                                
                                # Priority 1: Fill Code from Name
                                if name and name in h_c_map:
                                    row['Manual_Hazard_Item_CD'] = h_c_map.get(name)
                                # Priority 2: Fill Name from Code
                                elif code and code in h_rev_map:
                                    name = h_rev_map.get(code)
                                    row['Manual_Hazard_Item'] = name
                                
                                if name and name in h_m_map:
                                    row['Manual_Class_M'] = h_m_map.get(name)
                                    row['Manual_Class_L'] = h_l_map.get(name)
                                return row
                            merged = merged.apply(enrich_haz, axis=1)
                    except Exception as e:
                        st.warning(f"FDA Enrichment failed: {e}")

                # Update current_df with merged data (Respects Nulls unlike .update())
                common_idx = merged.index.intersection(current_df.index)
                if not common_idx.empty:
                    current_df.loc[common_idx, merged.columns] = merged.loc[common_idx]
                if not new_idx.empty:
                    current_df = pd.concat([current_df, merged.loc[new_idx]])
                
                # Write to disk
                current_df.to_parquet(file_path, engine='pyarrow', compression='snappy')
                st.session_state[f"edit_v_{selected_name}"] += 1
                st.cache_data.clear()
                st.toast(f"âœ… {selected_name} ëª¨ë“  ë³€ê²½ì‚¬í•­ ì €ì¥ ì™„ë£Œ!", icon="ğŸ’¾")
                time.sleep(1.5)
                st.rerun()
            except Exception as e:
                st.error(f"ì €ì¥ ì‹¤íŒ¨: {e}")

        @st.dialog("âš ï¸ ì‚­ì œ í™•ì¸")
        def show_delete_confirm(nuke_df, master_df, delta):
            st.warning("ì •ë§ ì•„ë˜ í•­ëª©ë“¤ì„ ì‚­ì œí•˜ì‹œê² ìŠµë‹ˆê¹Œ?")
            for idx, row in nuke_df.iterrows():
                st.markdown(f"**[{idx}]**")
                # Show key identifying columns or all columns
                for col in nuke_df.columns:
                    if col != 'ìˆ˜ë™ê³ ì •ì—¬ë¶€':
                        st.text(f"{col} : {row.get(col, '-')}")
                st.markdown("---")
            
            c1, c2 = st.columns(2)
            if c1.button("ğŸ”¥ ì‚­ì œ ì§„í–‰", type="primary", width="stretch"):
                perform_final_save(master_df, delta, edited_raw)
            if c2.button("ì·¨ì†Œ", width="stretch"):
                st.rerun()

        # 3. Save Button
        st.markdown("---")
        if st.button(f"ğŸ’¾ {selected_name} ëª¨ë“  ë³€ê²½ì‚¬í•­ ì €ì¥", type="primary", width="stretch"):
            changes = st.session_state.get(ed_key, {})
            d_idx = changes.get('deleted_rows', [])
            if d_idx:
                show_delete_confirm(display_df.iloc[d_idx], df_full, changes)
            else:
                perform_final_save(df_full, changes, edited_raw)
                
    except Exception as e:
        st.error(f"ë°ì´í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
