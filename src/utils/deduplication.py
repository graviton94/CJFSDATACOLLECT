import pandas as pd
from pathlib import Path
from src.schema import generate_record_id, UNIFIED_SCHEMA

def merge_and_deduplicate(new_df: pd.DataFrame, data_dir: Path = Path("data/hub")) -> pd.DataFrame:
    """
    ê¸°ì¡´ Parquet íŒŒì¼ê³¼ ë³‘í•©í•˜ë©° ì¤‘ë³µì„ ì œê±°í•©ë‹ˆë‹¤.
    Unique Key ê¸°ì¤€: data_source + source_detail
    """
    file_path = data_dir / "hub_data.parquet"
    
    if new_df.empty:
        return new_df

    # ì‹ ê·œ ë°ì´í„°ì— ì„ì‹œ ID ìƒì„±
    new_df['temp_id'] = new_df.apply(
        lambda x: generate_record_id(x['data_source'], x['source_detail']), axis=1
    )
    
    if not file_path.exists():
        # ê¸°ì¡´ íŒŒì¼ ì—†ìœ¼ë©´ ì „ì²´ ì €ì¥ (temp_id ì œê±° í›„)
        return new_df.drop(columns=['temp_id'])
    
    try:
        # ê¸°ì¡´ ë°ì´í„° ë¡œë“œ
        existing_df = pd.read_parquet(file_path)
        
        # ê¸°ì¡´ ë°ì´í„°ì—ë„ ì„ì‹œ ID ìƒì„± (ë§Œì•½ ì—†ë‹¤ë©´)
        existing_df['temp_id'] = existing_df.apply(
            lambda x: generate_record_id(x['data_source'], x['source_detail']), axis=1
        )
        
        # ì¤‘ë³µ ì œê±° ë¡œì§: ê¸°ì¡´ IDì— ì—†ëŠ” ê²ƒë§Œ ì‹ ê·œë¡œ ê°„ì£¼
        existing_ids = set(existing_df['temp_id'])
        non_duplicate_df = new_df[~new_df['temp_id'].isin(existing_ids)]
        
        print(f"   ğŸ” Deduplication: {len(new_df)} incoming -> {len(non_duplicate_df)} new unique records.")
        
        # ë³‘í•©
        combined_df = pd.concat([existing_df, non_duplicate_df], ignore_index=True)
        
        # ì„ì‹œ ID ì œê±° ë° ë°˜í™˜
        return combined_df.drop(columns=['temp_id'])
        
    except Exception as e:
        print(f"âš ï¸ Deduplication Error: {e}. Appending without check.")
        return new_df.drop(columns=['temp_id'])